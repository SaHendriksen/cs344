{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think deep neural networks will continue to provide breakthroughs, if they don’t get crucified by the public as trying to create machines that will take over the world. While deep neural networks are meant to simulate the way human brains work, they are no where near the level of human intelligence – they don’t possess their own “intelligence”. Through many layers of neurons and weights it uses known data to get to the most accurate neural network. I think that as long as the public doesn’t rule deep neural networks – and AI as a whole – out as possible solutions to problems because of a fear of something they don’t yet understand, deep neural networks offer solutions to many problems.\n",
    "\n",
    "Because of the way they are created and can be used, neural networks are able to be applied to many situations and the options are only increasing. For example, neural networks are being used in cancer diagnosis and are making it easier to predict sooner and get treatment to those who need it while it is still in the early stages. Deep neural networks also possess the ability to keep us safer through their use in driverless cars. But the uses can be more trivial like suggesting which movie we should watch next based off of previous choices. So as these different examples show, there are many and widespread uses for deep neural networks and more to discover.\n",
    "\n",
    "However, deep learning still isn’t able to exhibit other human qualities and as a result isn’t able to automate ordinary human activities. To me this doesn’t point to deep learning being a complete bust. Instead, I think it is an acknowledgement that while it offers many solutions, it is still a mathematical algorithm for classifying information and presenting results based on previous information. This doesn’t mean we should completely throw it out, instead it points to another undiscovered area that needs to be explored. How to get that step of automation, and once we get close to it, if we should actually execute it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the image files below are not displaying correctly (every time I closed the Jupyter notebook it stops working), please see the two images in the Homework 4 folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![file1-15.jpeg](attachment:file1-15.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![file-34.jpeg](attachment:file-34.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/srh34/workspace/cs344/venv/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /home/srh34/workspace/cs344/venv/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 42s 705us/step - loss: 0.5364 - acc: 0.8013\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 42s 702us/step - loss: 0.3320 - acc: 0.8791\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 42s 701us/step - loss: 0.2836 - acc: 0.8950\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 42s 700us/step - loss: 0.2528 - acc: 0.9074\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 42s 705us/step - loss: 0.2304 - acc: 0.9158\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 42s 707us/step - loss: 0.2107 - acc: 0.9216\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 42s 705us/step - loss: 0.1942 - acc: 0.9286\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 43s 709us/step - loss: 0.1812 - acc: 0.9335\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 38s 639us/step - loss: 0.1668 - acc: 0.9386\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 42s 706us/step - loss: 0.1555 - acc: 0.9424\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 43s 712us/step - loss: 0.1453 - acc: 0.9467\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 42s 707us/step - loss: 0.1358 - acc: 0.9499\n",
      "10000/10000 [==============================] - 3s 267us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.30701296789050103, 0.9101]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "# Configure a convnet with 3 layers of convolutions and max pooling.\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "\n",
    "# Add layers to flatten the 2D image and then do a 10-way classification.\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=12, batch_size=64)\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
