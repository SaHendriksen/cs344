Sarah Hendriksen
CS 344
Lab 10
Exercise 10.3

a) A confusion matrix shows which classes were misclassified as other classes. In this case the confusion matrix shows
which numbers get confused for each other. The confusion matrix shows which numbers are "confused" for each other
through a chart with a gray scale indicating the percentage. Diagonally down the chart indicate 1 (or near 1) because
those are the boxes that correspond to a number being confused for itself - something we hope would be 100%. Other boxes
that indicate confusion with noticeably non-white colors (around the .1-.3 range) include 1 and 8, 2 and 7, 4 and 9, 3
and 5, 5 and 8, 4 and 7.

b) Tensorflow includes a feature called drop out which at different points in the filtering, removes pieces of the data
in order to reduce the likelihood of memorization rather than learning. This improves this model because it prevents it
from just memorizing the specific forms of the numbers it is being trained on.

    classifier = train_nn_classification_model(
        learning_rate=0.05,
        steps=1000,
        batch_size=30,
        hidden_units=[100, 100],
        training_examples=training_examples,
        training_targets=training_targets,
        validation_examples=validation_examples,
        validation_targets=validation_targets)

    Final accuracy (on validation data): 0.94

c) The biggest difference in the visualizations when the step is decreased to 10 from 1000, is that at 1000 you can see
some resemblance to a number, while at 10 it is a image of a bunch of different color pixels with no apparent order.