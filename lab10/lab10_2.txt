Sarah Hendriksen
CS 344
Lab 10
Exercise 10.2

a) It optimizes performance by modifying the learning rate adaptively for each coefficient in a model, monotonically
    lowering the effective learning rate. This works well for convex problems, but not always ideal for non-convex
    problem NN training.

b)
    TASK 1:
        def normalize_linear_scale(examples_dataframe):
          """Returns a version of the input `DataFrame` that has all its features normalized linearly."""
          processed_features = pd.DataFrame()
          processed_features["latitude"] = linear_scale(examples_dataframe["latitude"])
          processed_features["longitude"] = linear_scale(examples_dataframe["longitude"])
          processed_features["housing_median_age"] = linear_scale(examples_dataframe["housing_median_age"])
          processed_features["total_rooms"] = linear_scale(examples_dataframe["total_rooms"])
          processed_features["total_bedrooms"] = linear_scale(examples_dataframe["total_bedrooms"])
          processed_features["population"] = linear_scale(examples_dataframe["population"])
          processed_features["households"] = linear_scale(examples_dataframe["households"])
          processed_features["median_income"] = linear_scale(examples_dataframe["median_income"])
          processed_features["rooms_per_person"] = linear_scale(examples_dataframe["rooms_per_person"])
          return processed_features

        normalized_dataframe = normalize_linear_scale(preprocess_features(california_housing_dataframe))
        normalized_training_examples = normalized_dataframe.head(12000)
        normalized_validation_examples = normalized_dataframe.tail(5000)

        _ = train_nn_regression_model(
            my_optimizer=tf.train.GradientDescentOptimizer(learning_rate=0.007),
            steps=2500,
            batch_size=70,
            hidden_units=[10, 10],
            training_examples=normalized_training_examples,
            training_targets=training_targets,
            validation_examples=normalized_validation_examples,
            validation_targets=validation_targets)

        RMSE (on training data): 69.45
        RMSE (on validation data): 68.83


    TASK 2:
        _, adagrad_training_losses, adagrad_validation_losses = train_nn_regression_model(
            my_optimizer=tf.train.AdagradOptimizer(learning_rate=0.5),
            steps=500,
            batch_size=100,
            hidden_units=[10, 10],
            training_examples=normalized_training_examples,
            training_targets=training_targets,
            validation_examples=normalized_validation_examples,
            validation_targets=validation_targets)

        Final RMSE (on training data):   69.75
        Final RMSE (on validation data): 69.32

        _, adam_training_losses, adam_validation_losses = train_nn_regression_model(
            my_optimizer=tf.train.AdamOptimizer(learning_rate=0.009),
            steps=500,
            batch_size=100,
            hidden_units=[10, 10],
            training_examples=normalized_training_examples,
            training_targets=training_targets,
            validation_examples=normalized_validation_examples,
            validation_targets=validation_targets)

        Final RMSE (on training data):   70.23
        Final RMSE (on validation data): 69.40

        plt.ylabel("RMSE")
        plt.xlabel("Periods")
        plt.title("Root Mean Squared Error vs. Periods")
        plt.plot(adagrad_training_losses, label='Adagrad training')
        plt.plot(adagrad_validation_losses, label='Adagrad validation')
        plt.plot(adam_training_losses, label='Adam training')
        plt.plot(adam_validation_losses, label='Adam validation')
        _ = plt.legend()


    TASK 3:
        def normalize(examples_dataframe):
          processed_features = pd.DataFrame()

          processed_features["households"] = log_normalize(examples_dataframe["households"])
          processed_features["median_income"] = log_normalize(examples_dataframe["median_income"])
          processed_features["total_bedrooms"] = log_normalize(examples_dataframe["total_bedrooms"])

          processed_features["latitude"] = linear_scale(examples_dataframe["latitude"])
          processed_features["longitude"] = linear_scale(examples_dataframe["longitude"])
          processed_features["housing_median_age"] = linear_scale(examples_dataframe["housing_median_age"])

          processed_features["population"] = linear_scale(clip(examples_dataframe["population"], 0, 5000))
          processed_features["rooms_per_person"] = linear_scale(clip(examples_dataframe["rooms_per_person"], 0, 5))
          processed_features["total_rooms"] = linear_scale(clip(examples_dataframe["total_rooms"], 0, 10000))

          return processed_features

        normalized_dataframe = normalize(preprocess_features(california_housing_dataframe))
        normalized_training_examples = normalized_dataframe.head(12000)
        normalized_validation_examples = normalized_dataframe.tail(5000)

        _ = train_nn_regression_model(
            my_optimizer=tf.train.GradientDescentOptimizer(learning_rate=0.12),
            steps=1500,
            batch_size=60,
            hidden_units=[10, 10],
            training_examples=normalized_training_examples,
            training_targets=training_targets,
            validation_examples=normalized_validation_examples,
            validation_targets=validation_targets)

        Final RMSE (on training data):   84.51
        Final RMSE (on validation data): 83.20